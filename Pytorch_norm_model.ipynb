{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce64cb30-e347-4b09-9b02-73de8fcea1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import time\n",
    "import warnings\n",
    "import gc\n",
    "from hurst import compute_Hc\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import iirfilter, filtfilt\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.metrics import KLDivergence\n",
    "# from scipy.stats import skew, kurtosis\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42412e21-1f4e-4604-aad7-fba4d67e759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fabien's paths\n",
    "directory = 'D:/Kaggle/2024/Harmful_brain_activity_classification/train_models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62af29e9-8683-44b9-8d2d-34bb8ee0d1c8",
   "metadata": {},
   "source": [
    "# PyTorch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "375ef842-f505-4f3c-90e2-f4790d2d9417",
   "metadata": {},
   "outputs": [],
   "source": [
    "verif_data = pd.read_csv(directory + \"verif_headers_order.csv\")\n",
    "verif_headers_order = verif_data.columns\n",
    "\n",
    "class cScaler:\n",
    "    def __init__(self):\n",
    "        self.full_train = StandardScaler()\n",
    "\n",
    "file = open(directory + \"standard_scaler.pickle\", 'rb')\n",
    "scaler = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dddf4db-a808-494d-98d9-f236a87595a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106800, 1430)\n",
      "(106800, 1410)\n"
     ]
    }
   ],
   "source": [
    "testdata = pd.read_parquet(directory + \"Combined_Features_wf_all.parquet\")\n",
    "\n",
    "Y_data = testdata.iloc[:,9:15].values\n",
    "print(testdata.shape)\n",
    "\n",
    "testdata = testdata.iloc[:,15:]\n",
    "testdata = testdata.select_dtypes(include=[np.number])\n",
    "testdata = testdata.drop(\"Total_votes\", axis =1)\n",
    "print(testdata.shape)\n",
    "\n",
    "# strategy for missing values\n",
    "testdata = testdata.replace(np.nan, 0)\n",
    "\n",
    "Y_data = Y_data / np.sum(Y_data,axis=1,keepdims=True)\n",
    "X_cols = testdata.select_dtypes(include=[np.number]).keys()\n",
    "X_data = testdata.select_dtypes(include=[np.number])\n",
    "X_data = scaler.full_train.transform(X_data) # standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2104d93-3f37-4f65-8b99-f8746d8204d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataT = torch.tensor(X_data).float()\n",
    "labelsT = torch.tensor(Y_data).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96ee74dd-879f-4d51-afe0-0f8a38bcd6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBnormModel(Datain):\n",
    "\n",
    "    class BnormModel(nn.Module):\n",
    "        def __init__(self):\n",
    "             super().__init__()\n",
    "\n",
    "             ### input layer\n",
    "             self.input = nn.Linear(Datain.shape[1],1500)\n",
    "             self.bnin = nn.BatchNorm1d(1500)\n",
    "             ### hidden layers\n",
    "             self.fc1 = nn.Linear(1500,2000)\n",
    "             self.bn1 = nn.BatchNorm1d(2000)\n",
    "             self.fc2 = nn.Linear(2000,1500)\n",
    "             self.bn2 = nn.BatchNorm1d(1500)\n",
    "             self.fc3 = nn.Linear(1500,200)\n",
    "             self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "             ### output layer\n",
    "             self.output = nn.Linear(200,6)\n",
    "\n",
    "        # forward pass\n",
    "        def forward(self,x):\n",
    "             x = F.relu( self.bnin(self.input(x)) )\n",
    "             x = F.relu( self.bn1(self.fc1(x)) )\n",
    "             # x = self.dropout(x)\n",
    "             x = F.relu( self.bn2(self.fc2(x)) )\n",
    "             # x = self.dropout(x)\n",
    "             x = F.relu( self.fc3(x) )\n",
    "             return torch.log_softmax( self.output(x),axis=1 )\n",
    "            \n",
    "    # create the model instance\n",
    "    net = BnormModel()\n",
    "\n",
    "    # loss function\n",
    "    # lossfun = nn.NLLLoss()\n",
    "    lossfun = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.Adam(net.parameters(),lr=1e-4, weight_decay=1e-3)\n",
    "\n",
    "    return net, lossfun, optimizer\n",
    "\n",
    "# Load the model\n",
    "Norm_Net_trained, lossfun, optimizer = createBnormModel(X_data)\n",
    "modelinfo = torch.load(directory + 'Trained_Norm_Net')\n",
    "Norm_Net_trained.load_state_dict(modelinfo['model_state_dict'])\n",
    "Norm_Net_trained.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e10409-925e-40d9-8dff-7d0cae51085c",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f6f430d-456e-4055-a8f1-4cbfdb3e9e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assessment metrics\n",
    "def log(x):\n",
    "    x[x == 0] = 1e-15\n",
    "    x[x == 1] = 1-1e-15\n",
    "    return np.log(x)\n",
    "\n",
    "\n",
    "def JensenShannonDiv(true_y, pred_y): # Jensen-Shannon Divergence https://towardsdatascience.com/how-to-understand-and-use-jensen-shannon-divergence-b10e11b03fd6\n",
    "    # removing 0 to avoid divisions by 0.\n",
    "    true_y[true_y == 0] = 1e-15\n",
    "    pred_y[pred_y == 0] = 1e-15\n",
    "    # sum to 1\n",
    "    true_y = true_y.T / np.sum(true_y, axis = 1)\n",
    "    true_y = true_y.T\n",
    "    pred_y = pred_y.T / np.sum(pred_y, axis = 1)\n",
    "    pred_y = pred_y.T\n",
    "    JSD1 = pred_y*log(2* pred_y/ (pred_y+true_y))\n",
    "    JSD2 = true_y*log(2* true_y/ (pred_y+true_y))\n",
    "    JSD = 0.5*np.sum(JSD1, axis = 1) + 0.5*np.sum(JSD2, axis = 1)\n",
    "    return np.nanmean(JSD)\n",
    "\n",
    "\n",
    "# competition metric? \n",
    "def kl_divergence(solution, submission, epsilon = 1e-15, micro_average = False, sample_weights = None):\n",
    "    if not isinstance(solution, pd.DataFrame): solution = pd.DataFrame(solution)\n",
    "    if not isinstance(submission, pd.DataFrame): submission = pd.DataFrame(submission)   \n",
    "\n",
    "    for col in solution.columns:\n",
    "\n",
    "        if not pd.api.types.is_float_dtype(solution[col]):\n",
    "            solution[col] = solution[col].astype(float)\n",
    "        submission[col] = np.clip(submission[col], epsilon, 1 - epsilon)\n",
    "\n",
    "        y_nonzero_indices = solution[col] != 0 \n",
    "        solution[col] = solution[col].astype(float)\n",
    "        solution.loc[y_nonzero_indices, col] = solution.loc[y_nonzero_indices, col] * \\\n",
    "                                                np.log(solution.loc[y_nonzero_indices, col] / submission.loc[y_nonzero_indices, col])\n",
    "        \n",
    "        solution.loc[~y_nonzero_indices, col] = 0\n",
    "\n",
    "    if micro_average:\n",
    "        return np.average(solution.sum(axis=1))#, weights=sample_weights)\n",
    "    else:\n",
    "        return np.average(solution.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdf373ce-10e3-48ca-8b4a-1b5767dd74e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred = np.array(Norm_Net_trained(dataT))\n",
    "\n",
    "pred = np.exp(pred)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "287db7c6-7d01-4fb8-9fee-31490c6ad16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch KLD loss: -1.1043344736099243\n",
      "Jensen Shannon Div: 0.0320485420525074\n",
      "KL Divergence: 0.02341656037011554\n",
      "Keras KLD loss: 0.1404956579208374\n"
     ]
    }
   ],
   "source": [
    "print(f'Pytorch KLD loss: {lossfun(torch.tensor(pred).float(), labelsT)}')\n",
    "print(f'Jensen Shannon Div: {JensenShannonDiv(np.array(labelsT), pred)}')\n",
    "print(f'KL Divergence: {kl_divergence(np.array(labelsT), pred)}')\n",
    "kld = KLDivergence()\n",
    "print(f'Keras KLD loss: {kld(np.array(labelsT), pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31cb574-3f0e-499f-bdb8-18dd3b9b86c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
